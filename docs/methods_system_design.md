# Methods & System Design

## Purpose
- Research bot to study AI-assisted, harm-reduction-oriented replies about microdosing/psychedelics in Reddit communities, with a mandatory human-in-the-loop.
- Not for promotion, sales, or growth; low-volume, rule-abiding interactions only.
- Research framing: “Designing an AI-Assisted Reddit Bot for Harm-Reduction Microdosing Education: A Case Study in Community-Embedded Automation.”

## Research Questions (framing)
- RQ1: Can an AI-assisted Reddit bot provide consistent, harm-reduction-focused microdosing information in relevant communities?
- RQ2: How do users respond (upvotes, replies, sentiment) to educational comments generated by an AI vs. manually written comments?
- RQ3: What ethical and practical constraints arise when deploying AI agents into online mental health & psychedelic spaces?

## Safety Constraints (enforced in code/process)
- No medical or dosing advice; no microdosing protocols/schedules; no encouragement of illegal activity.
- No links or product/brand promotion.
- Human approval required before posting; posting disabled by default.
- Low volume (approval cap, limited scans), respect subreddit rules and Reddit’s policies.
- Mock mode for development without API access.

## Architecture Overview
- **Config**: `.env` provides Reddit creds; toggles: `MOCK_MODE`, `ENABLE_POSTING`, `USE_LLM`, `RUN_ID`, optional `OPENAI_API_KEY`.
- **Auth + mock fallback**: If auth fails or `MOCK_MODE=1`, scripts use hard-coded mock posts so logic stays testable.
- **Keyword scan**: `bot_step2_keywords.py` filters recent posts in target subs for microdosing/psychedelic harm-reduction `KEYWORDS` and prints matches. Default subreddits include `test`, `microdosing`, `psilocybin`, `mentalhealth`, `ADHD`, `Psychonaut` (swap to approved subs as needed).
- **Reply generator**: `bot_step3_replies.py` uses a deterministic safe stub; optionally an LLM (`USE_LLM=1`) with a strict safety prompt (no dosing/protocols, no illegal encouragement, no links/promos). Any LLM failure falls back to the stub.
- **Approval gate**: CLI prompt `Post this reply? (y/n)`; approval cap per run; posting disabled unless explicitly enabled.
- **Posting guard**: Dry-run by default. Actual posting only when `ENABLE_POSTING=1` and user approves.
- **Logging**: `bot_step3_replies.py` appends to `bot_logs.csv` (run_id, mode, post metadata, matched keywords, reply text, approval decision, posted flag, comment_id, error).
- **Metrics**: `bot_step4_metrics.py` reads `bot_logs.csv`, fetches posted comments, records score and replies_count to `bot_metrics.csv`.

## Run Instructions (short)
- Install deps: `pip install praw python-dotenv` (and `openai` if using LLM).
- Set `.env`:
  - Required: Reddit creds, `REDDIT_USER_AGENT` descriptive.
  - Optional toggles: `MOCK_MODE=1` (offline), `ENABLE_POSTING=1` (allow replies), `USE_LLM=1` + `OPENAI_API_KEY`, `RUN_ID` (label).
- Dry-run / mock:
  - `python bot_step1.py` (auth check + mock posts if enabled).
  - `python bot_step2_keywords.py` (keyword scan; mock fallback).
  - `python bot_step3_replies.py` (matches + suggested replies + approval prompts; logs to `bot_logs.csv`).
- Metrics:
  - After live posts exist: `python bot_step4_metrics.py` (skips in mock mode) to append `bot_metrics.csv`.

## Data Collected
- `bot_logs.csv`: per match/reply attempt (run_id, mode, subreddit, post_id, title, matched_keywords, reply_text, approved, posted, comment_id, error).
- `bot_metrics.csv`: per posted comment check (timestamp_checked_utc, run_id, subreddit, post_id, comment_id, title, matched_keywords, score, replies_count, error).
